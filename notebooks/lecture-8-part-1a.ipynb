{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3ea2c52-3ead-4484-8a13-59ff459b0f78",
      "metadata": {
        "id": "e3ea2c52-3ead-4484-8a13-59ff459b0f78"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import requests\n",
        "\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import compose, datasets, ensemble, linear_model, metrics\n",
        "from sklearn import model_selection, neighbors, pipeline\n",
        "from sklearn import preprocessing, svm, tree"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be202dc8-9556-4c87-a70a-06b1df636521",
      "metadata": {
        "id": "be202dc8-9556-4c87-a70a-06b1df636521"
      },
      "source": [
        "# Ensemble Learning\n",
        "\n",
        "Building a model on top of many other models is called [ensemble](https://scikit-learn.org/stable/modules/ensemble.html) learning and it is often a great approach to improve the predictions of your machine learning pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and prepare the data"
      ],
      "metadata": {
        "id": "a5lBwoGjA1nR"
      },
      "id": "a5lBwoGjA1nR"
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_data = datasets.load_diabetes(\n",
        "    as_frame=True,\n",
        "    scaled=False\n",
        ")"
      ],
      "metadata": {
        "id": "UgXXim0f-q89"
      },
      "id": "UgXXim0f-q89",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_df = diabetes_data.data\n",
        "target = diabetes_data.target"
      ],
      "metadata": {
        "id": "eE6XXQAD_cyL"
      },
      "id": "eE6XXQAD_cyL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_df.head()"
      ],
      "metadata": {
        "id": "gOyWyB5pANJj"
      },
      "id": "gOyWyB5pANJj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "id": "Trp1wsEQ_qk4"
      },
      "id": "Trp1wsEQ_qk4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preprocessing"
      ],
      "metadata": {
        "id": "T8HggBfUA57r"
      },
      "id": "T8HggBfUA57r"
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_0 = compose.make_column_transformer(\n",
        "    (\n",
        "        preprocessing.OneHotEncoder(\n",
        "            drop=\"first\",\n",
        "            dtype=np.uint8,\n",
        "            sparse_output=False,\n",
        "        ),\n",
        "        [\"sex\"]\n",
        "    ),\n",
        "    remainder=\"drop\",\n",
        "    verbose=True,\n",
        "    verbose_feature_names_out=False\n",
        ")\n",
        "\n",
        "transformer_1 = compose.make_column_transformer(\n",
        "    (\n",
        "        preprocessing.StandardScaler(),\n",
        "        [\"age\", \"bmi\", \"bp\", \"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"s6\"]\n",
        "    ),\n",
        "    remainder=\"drop\",\n",
        "    verbose=True,\n",
        "    verbose_feature_names_out=False\n",
        ")\n",
        "\n",
        "features_preprocessor = pipeline.make_union(\n",
        "    transformer_0,\n",
        "    transformer_1,\n",
        "    verbose=True,\n",
        "    n_jobs=-1\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "target_preprocessor = preprocessing.FunctionTransformer(\n",
        "    func=np.log,\n",
        "    inverse_func=np.exp\n",
        ")"
      ],
      "metadata": {
        "id": "ZWlWB2IMAi2D"
      },
      "id": "ZWlWB2IMAi2D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature engineering"
      ],
      "metadata": {
        "id": "hlWSBTKnBHR0"
      },
      "id": "hlWSBTKnBHR0"
    },
    {
      "cell_type": "code",
      "source": [
        "feature_engineering = preprocessing.PolynomialFeatures(\n",
        "    degree=2,\n",
        "    include_bias=False,\n",
        "    interaction_only=False\n",
        ").set_output(transform=\"pandas\")\n"
      ],
      "metadata": {
        "id": "Os4y0KG3BKVo"
      },
      "id": "Os4y0KG3BKVo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Voting"
      ],
      "metadata": {
        "id": "s41Wlio1_e3t"
      },
      "id": "s41Wlio1_e3t"
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble.VotingRegressor?"
      ],
      "metadata": {
        "id": "HruXG_iY_eCu"
      },
      "id": "HruXG_iY_eCu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voting_regressor = ensemble.VotingRegressor(\n",
        "    estimators=[\n",
        "        (\"sgd_regressor\", linear_model.SGDRegressor()),\n",
        "        (\"k_neighbors_regressor\", neighbors.KNeighborsRegressor()),\n",
        "        (\"linear_svr\", svm.LinearSVR()),\n",
        "        (\"tree\", tree.DecisionTreeRegressor()),\n",
        "    ],\n",
        "    weights=None,\n",
        "    n_jobs=-1,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "voting_regressor_pipeline = pipeline.make_pipeline(\n",
        "    features_preprocessor,\n",
        "    feature_engineering,\n",
        "    voting_regressor,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "fnTRsbybBg4X"
      },
      "id": "fnTRsbybBg4X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voting_regressor_pipeline"
      ],
      "metadata": {
        "id": "JUkcpfiREHN_"
      },
      "id": "JUkcpfiREHN_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_scores = model_selection.cross_val_score(\n",
        "    voting_regressor_pipeline,\n",
        "    features_df,\n",
        "    target,\n",
        "    cv=5,\n",
        "    n_jobs=1,\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ")"
      ],
      "metadata": {
        "id": "nrcoFpEuEKx-"
      },
      "id": "nrcoFpEuEKx-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(-ensemble_scores)"
      ],
      "metadata": {
        "id": "WxUIo8trFP5d"
      },
      "id": "WxUIo8trFP5d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Excercise\n",
        "\n",
        "Use cross validation to score each of the individual estimators included in the voting regressor above. Compare the results of our ensemble with the best individual model."
      ],
      "metadata": {
        "id": "t4EvqFlQFwA7"
      },
      "id": "t4EvqFlQFwA7"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9z78cDSzGP7h"
      },
      "id": "9z78cDSzGP7h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Solution"
      ],
      "metadata": {
        "id": "5k2Qzrh5GSWG"
      },
      "id": "5k2Qzrh5GSWG"
    },
    {
      "cell_type": "code",
      "source": [
        "_sgd_regressor_pipeline = pipeline.make_pipeline(\n",
        "    features_preprocessor,\n",
        "    feature_engineering,\n",
        "    linear_model.SGDRegressor()\n",
        ")\n",
        "\n",
        "sgd_regressor_scores = model_selection.cross_val_score(\n",
        "    _sgd_regressor_pipeline,\n",
        "    features_df,\n",
        "    target,\n",
        "    cv=5,\n",
        "    n_jobs=1,\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ")\n",
        "\n",
        "print(np.sqrt(-sgd_regressor_scores))"
      ],
      "metadata": {
        "id": "xY3X-RQPGUMu"
      },
      "id": "xY3X-RQPGUMu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_sgd_regressor_pipeline = pipeline.make_pipeline(\n",
        "    features_preprocessor,\n",
        "    feature_engineering,\n",
        "    linear_model.SGDRegressor()\n",
        ")\n",
        "\n",
        "sgd_regressor_scores = model_selection.cross_val_score(\n",
        "    _sgd_regressor_pipeline,\n",
        "    features_df,\n",
        "    target,\n",
        "    cv=5,\n",
        "    n_jobs=1,\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ")\n",
        "\n",
        "print(np.sqrt(-sgd_regressor_scores))"
      ],
      "metadata": {
        "id": "dr56D2g4GtbM"
      },
      "id": "dr56D2g4GtbM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_linear_svr_pipeline = pipeline.make_pipeline(\n",
        "    features_preprocessor,\n",
        "    feature_engineering,\n",
        "    svm.LinearSVR()\n",
        ")\n",
        "\n",
        "linear_svr_scores = model_selection.cross_val_score(\n",
        "    _linear_svr_pipeline,\n",
        "    features_df,\n",
        "    target,\n",
        "    cv=5,\n",
        "    n_jobs=1,\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ")\n",
        "\n",
        "print(np.sqrt(-linear_svr_scores))"
      ],
      "metadata": {
        "id": "f0tXoOGpGti_"
      },
      "id": "f0tXoOGpGti_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_neighbors_pipeline = pipeline.make_pipeline(\n",
        "    features_preprocessor,\n",
        "    feature_engineering,\n",
        "    neighbors.KNeighborsRegressor()\n",
        ")\n",
        "\n",
        "neighbors_scores = model_selection.cross_val_score(\n",
        "    _neighbors_pipeline,\n",
        "    features_df,\n",
        "    target,\n",
        "    cv=5,\n",
        "    n_jobs=1,\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ")\n",
        "\n",
        "print(np.sqrt(-neighbors_scores))"
      ],
      "metadata": {
        "id": "naEF59DKGttJ"
      },
      "id": "naEF59DKGttJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_tree_pipeline = pipeline.make_pipeline(\n",
        "    features_preprocessor,\n",
        "    feature_engineering,\n",
        "    tree.DecisionTreeRegressor()\n",
        ")\n",
        "\n",
        "tree_scores = model_selection.cross_val_score(\n",
        "    _tree_pipeline,\n",
        "    features_df,\n",
        "    target,\n",
        "    cv=5,\n",
        "    n_jobs=1,\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ")\n",
        "\n",
        "print(np.sqrt(-tree_scores))"
      ],
      "metadata": {
        "id": "MLNSkbb9HRJ_"
      },
      "id": "MLNSkbb9HRJ_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bagging and Pasting"
      ],
      "metadata": {
        "id": "9KzgFVwiIS9i"
      },
      "id": "9KzgFVwiIS9i"
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble.BaggingRegressor?"
      ],
      "metadata": {
        "id": "8CL3nxnQIWgl"
      },
      "id": "8CL3nxnQIWgl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bagging_regressor = ensemble.BaggingRegressor(\n",
        "    estimator=tree.DecisionTreeRegressor(),\n",
        "    n_estimators=10,\n",
        "    max_samples=0.8,\n",
        "    bootstrap=True,\n",
        "    max_features=1.0,\n",
        "    bootstrap_features=False,\n",
        "    oob_score=True,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "gL8zD0DzI4_o"
      },
      "id": "gL8zD0DzI4_o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bagging_regressor"
      ],
      "metadata": {
        "id": "xYUFXErRI5In"
      },
      "id": "xYUFXErRI5In",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = bagging_regressor.fit(features_df, target)"
      ],
      "metadata": {
        "id": "JvE_PUTCJ6NM"
      },
      "id": "JvE_PUTCJ6NM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oob_predictions = bagging_regressor.oob_prediction_\n",
        "metrics.mean_squared_error(\n",
        "    target,\n",
        "    oob_predictions,\n",
        "    squared=False\n",
        ")"
      ],
      "metadata": {
        "id": "ouvIVF2hJ_AI"
      },
      "id": "ouvIVF2hJ_AI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forests\n",
        "\n",
        "Letâ€™s try the [`ensemble.RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html). Random forests work by training many decision trees on random subsets of the features, then averaging the predictions made by each of the decision trees to arrive at an overall prediction."
      ],
      "metadata": {
        "id": "QbwPxCYZ-itX"
      },
      "id": "QbwPxCYZ-itX"
    },
    {
      "cell_type": "code",
      "source": [
        "_random_forest_pipeline = pipeline.make_pipeline(\n",
        "    features_preprocessor,\n",
        "    feature_engineering,\n",
        "    ensemble.RandomForestRegressor()\n",
        ")\n",
        "\n",
        "random_forest_scores = model_selection.cross_val_score(\n",
        "    _random_forest_pipeline,\n",
        "    features_df,\n",
        "    target,\n",
        "    cv=5,\n",
        "    n_jobs=1,\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ")\n",
        "\n",
        "print(np.sqrt(-random_forest_scores))"
      ],
      "metadata": {
        "id": "avN_PWO4-gIr"
      },
      "id": "avN_PWO4-gIr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "\n",
        "Compare the performance of the ExtraTreesRegressor with the RandomForestRegressor fit above."
      ],
      "metadata": {
        "id": "M6YaWx18MRs7"
      },
      "id": "M6YaWx18MRs7"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F962wdjlMlbm"
      },
      "id": "F962wdjlMlbm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Solution"
      ],
      "metadata": {
        "id": "P6y2VzgEMmKC"
      },
      "id": "P6y2VzgEMmKC"
    },
    {
      "cell_type": "code",
      "source": [
        "_extra_trees_pipeline = pipeline.make_pipeline(\n",
        "    features_preprocessor,\n",
        "    feature_engineering,\n",
        "    ensemble.ExtraTreesRegressor()\n",
        ")\n",
        "\n",
        "extra_trees_scores = model_selection.cross_val_score(\n",
        "    _extra_trees_pipeline,\n",
        "    features_df,\n",
        "    target,\n",
        "    cv=5,\n",
        "    n_jobs=1,\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ")\n",
        "\n",
        "print(np.sqrt(-extra_trees_scores))"
      ],
      "metadata": {
        "id": "g1giemWRMQ-V"
      },
      "id": "g1giemWRMQ-V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "\n",
        "Tune the hyperparameters of either the RandomForestRegressor or the ExtraTreesRegressor and see if you can get even better performance."
      ],
      "metadata": {
        "id": "KTsjMI9GBcv5"
      },
      "id": "KTsjMI9GBcv5"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "23U8OKzHDdsm"
      },
      "id": "23U8OKzHDdsm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Solution"
      ],
      "metadata": {
        "id": "HGGzJHQ7OYLn"
      },
      "id": "HGGzJHQ7OYLn"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fEm6n8GUOZdi"
      },
      "id": "fEm6n8GUOZdi",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
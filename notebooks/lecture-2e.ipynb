{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6G9EcyogkUT"
      },
      "source": [
        "# Fine-Tune Your Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import requests\n",
        "import tarfile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "\n",
        "\n",
        "def download_data(url, data_dir):\n",
        "    with open(data_dir / \"housing.tgz\", 'wb') as f:\n",
        "        response = requests.get(url)\n",
        "        f.write(response.content)\n",
        "\n",
        "\n",
        "def extract_data(data_dir):\n",
        "    with tarfile.open(data_dir / \"housing.tgz\") as tgz:\n",
        "        tgz.extractall(path=data_dir)\n",
        "\n",
        "\n",
        "# load the data\n",
        "url = \"https://github.com/ageron/data/raw/main/housing.tgz\"\n",
        "data_dir = pathlib.Path(\"./sample_data\")\n",
        "data_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "download_data(url, data_dir)\n",
        "extract_data(data_dir)\n",
        "housing_df = pd.read_csv(data_dir / \"housing\" / \"housing.csv\")\n",
        "\n",
        "# stratified sampling to match the income distribution\n",
        "housing_df[\"income_cat\"] = pd.cut(\n",
        "    housing_df[\"median_income\"],\n",
        "    bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
        "    labels=[0, 1, 2, 3, 4]\n",
        ")\n",
        "\n",
        "train_df, test_df = model_selection.train_test_split(\n",
        "    housing_df,\n",
        "    test_size=0.2,\n",
        "    stratify=housing_df.loc[:, \"income_cat\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_df.drop(\"income_cat\", axis=1, inplace=True)\n",
        "test_df.drop(\"income_cat\", axis=1, inplace=True)\n",
        "\n",
        "# split off the features and the target\n",
        "train_features_df = train_df.drop(\"median_house_value\", axis=1)\n",
        "train_targets = train_df.loc[:, \"median_house_value\"]"
      ],
      "metadata": {
        "id": "rqTg7YmRpNJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import base, cluster, compose, impute, metrics, pipeline, preprocessing\n",
        "\n",
        "\n",
        "class ClusterSimilarity(base.BaseEstimator, base.TransformerMixin):\n",
        "\n",
        "    def __init__(self, n_clusters=10, gamma=1.0, random_state=None):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.gamma = gamma\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def fit(self, X, y=None, sample_weight=None):\n",
        "        kmeans = cluster.KMeans(\n",
        "            self.n_clusters,\n",
        "            n_init=10,\n",
        "            random_state=self.random_state\n",
        "        )\n",
        "        self.kmeans_ = kmeans.fit(X, sample_weight=sample_weight)\n",
        "        return self  # always return self!\n",
        "\n",
        "    def transform(self, X):\n",
        "        similarities = (\n",
        "            metrics.pairwise\n",
        "                   .rbf_kernel(\n",
        "                       X,\n",
        "                       Y=self.kmeans_.cluster_centers_,\n",
        "                       gamma=self.gamma\n",
        "                   )\n",
        "        )\n",
        "        return similarities\n",
        "\n",
        "    def get_feature_names_out(self, names=None):\n",
        "        return [f\"cluster_{i:02d}_similarity\" for i in range(self.n_clusters)]\n",
        "\n",
        "\n",
        "def column_ratio(df):\n",
        "    return df.iloc[:, 0] / df.iloc[:, 1]\n",
        "\n",
        "\n",
        "def ratio_name(function_transformer, feature_names_in):\n",
        "    return [\"ratio\"]  # feature names out\n",
        "\n",
        "\n",
        "def make_ratio_pipeline():\n",
        "    ratio_pipeline = (\n",
        "        pipeline.make_pipeline(\n",
        "            impute.SimpleImputer(strategy=\"median\"),\n",
        "            preprocessing.FunctionTransformer(column_ratio, feature_names_out=ratio_name),\n",
        "            preprocessing.StandardScaler(),\n",
        "            verbose=True\n",
        "        ).set_output(\n",
        "            transform=\"pandas\"\n",
        "        )\n",
        "    )\n",
        "    return ratio_pipeline\n",
        "\n",
        "\n",
        "log_transform_pipeline = (\n",
        "    pipeline.make_pipeline(\n",
        "        impute.SimpleImputer(strategy=\"median\"),\n",
        "        preprocessing.FunctionTransformer(np.log, np.exp, feature_names_out=\"one-to-one\"),\n",
        "        preprocessing.StandardScaler()\n",
        "    ).set_output(\n",
        "        transform=\"pandas\"\n",
        "    )\n",
        ")\n",
        "\n",
        "cluster_similarity = (\n",
        "    ClusterSimilarity(\n",
        "        n_clusters=10,\n",
        "        gamma=1.,\n",
        "        random_state=42\n",
        "    ).set_output(\n",
        "        transform=\"pandas\"\n",
        "    )\n",
        ")\n",
        "\n",
        "categorical_pipeline = (\n",
        "    pipeline.make_pipeline(\n",
        "        impute.SimpleImputer(strategy=\"most_frequent\"),\n",
        "        preprocessing.OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
        "    ).set_output(\n",
        "        transform=\"pandas\"\n",
        "    )\n",
        ")\n",
        "\n",
        "default_numeric_pipeline = (\n",
        "    pipeline.make_pipeline(\n",
        "        impute.SimpleImputer(strategy=\"median\"),\n",
        "        preprocessing.StandardScaler(),\n",
        "        verbose=True\n",
        "    ).set_output(\n",
        "        transform=\"pandas\"\n",
        "    )\n",
        ")\n",
        "\n",
        "preprocessing_pipeline = (\n",
        "    compose.ColumnTransformer(\n",
        "        [\n",
        "            (\"bedrooms\", make_ratio_pipeline(), [\"total_bedrooms\", \"total_rooms\"]),\n",
        "            (\"rooms_per_house\", make_ratio_pipeline(), [\"total_rooms\", \"households\"]),\n",
        "            (\"people_per_house\", make_ratio_pipeline(), [\"population\", \"households\"]),\n",
        "            (\"log\", log_transform_pipeline, [\"total_bedrooms\", \"total_rooms\", \"population\", \"households\", \"median_income\"]),\n",
        "            (\"geo\", cluster_similarity, [\"latitude\", \"longitude\"]),\n",
        "            (\"categorical\", categorical_pipeline, compose.make_column_selector(dtype_include=object)),\n",
        "        ],\n",
        "        n_jobs=-1,\n",
        "        remainder=default_numeric_pipeline,\n",
        "        verbose=True\n",
        "    ).set_output(\n",
        "        transform=\"pandas\"\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "LhKwBlQIpSmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import ensemble\n",
        "\n",
        "\n",
        "random_forest_pipeline = (\n",
        "    pipeline.Pipeline(\n",
        "        [\n",
        "            (\"preprocessing\", preprocessing_pipeline),\n",
        "            (\"random_forest\", ensemble.RandomForestRegressor(random_state=42))\n",
        "        ],\n",
        "        verbose=True\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "geyf-I0kpb1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX5mJFQpgkUT"
      },
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_selection.GridSearchCV?"
      ],
      "metadata": {
        "id": "ujD7JBwCqpWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb0ddQ7fgkUT"
      },
      "outputs": [],
      "source": [
        "param_grid = [\n",
        "    {'preprocessing__geo__n_clusters': [5, 8, 10],\n",
        "     'random_forest__max_features': [4, 6, 8]},\n",
        "    {'preprocessing__geo__n_clusters': [10, 15],\n",
        "     'random_forest__max_features': [6, 8, 10]},\n",
        "]\n",
        "\n",
        "grid_search_cv = model_selection.GridSearchCV(\n",
        "    random_forest_pipeline,\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    scoring='neg_root_mean_squared_error',\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_cv"
      ],
      "metadata": {
        "id": "qNu2zbggqIeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = grid_search_cv.fit(train_features_df, train_targets)"
      ],
      "metadata": {
        "id": "ZghvHPtoqLEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIh_32DlgkUU"
      },
      "source": [
        "You can get the full list of hyperparameters available for tuning by looking at..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7fQsCK2gkUU"
      },
      "outputs": [],
      "source": [
        "(\n",
        "    grid_search_cv.get_params()\n",
        "                  .keys()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb_OZkN0gkUU"
      },
      "source": [
        "The best hyperparameter combination found:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-L-wgMYagkUU"
      },
      "outputs": [],
      "source": [
        "grid_search_cv.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMAZ4QfsgkUU"
      },
      "outputs": [],
      "source": [
        "grid_search_cv.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtoZY45NgkUU"
      },
      "source": [
        "Let's look at the score of each hyperparameter combination tested during the grid search:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqprdHavgkUU"
      },
      "outputs": [],
      "source": [
        "cv_results_df = pd.DataFrame(grid_search_cv.cv_results_)\n",
        "cv_results_df.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results_df"
      ],
      "metadata": {
        "id": "7H8g16txuURX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY5_A6n5gkUU"
      },
      "source": [
        "## Randomized Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsTRJCH8gkUU"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "\n",
        "param_distribs = {\n",
        "    'preprocessing__geo__n_clusters': stats.randint(low=3, high=50),\n",
        "    'random_forest__max_features': stats.randint(low=2, high=20)\n",
        "}\n",
        "\n",
        "randomized_search_cv = model_selection.RandomizedSearchCV(\n",
        "    random_forest_pipeline,\n",
        "    param_distributions=param_distribs,\n",
        "    n_iter=10,\n",
        "    cv=3,\n",
        "    scoring='neg_root_mean_squared_error',\n",
        "    random_state=42,\n",
        "    verbose=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_search_cv"
      ],
      "metadata": {
        "id": "v0fgDATMu22R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = randomized_search_cv.fit(train_features_df, train_targets)"
      ],
      "metadata": {
        "id": "ZgD5VNc8u29N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHr8SkomgkUU"
      },
      "outputs": [],
      "source": [
        "cv_results_df = pd.DataFrame(randomized_search_cv.cv_results_)\n",
        "cv_results_df.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results_df"
      ],
      "metadata": {
        "id": "U3D5hGpKvTzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89bBNvksgkUV"
      },
      "source": [
        "**Bonus section: how to choose the sampling distribution for a hyperparameter**\n",
        "\n",
        "* `scipy.stats.randint(a, b+1)`: for hyperparameters with _discrete_ values that range from a to b, and all values in that range seem equally likely.\n",
        "* `scipy.stats.uniform(a, b)`: this is very similar, but for _continuous_ hyperparameters.\n",
        "* `scipy.stats.geom(1 / scale)`: for discrete values, when you want to sample roughly in a given scale. E.g., with scale=1000 most samples will be in this ballpark, but ~10% of all samples will be <100 and ~10% will be >2300.\n",
        "* `scipy.stats.expon(scale)`: this is the continuous equivalent of `geom`. Just set `scale` to the most likely value.\n",
        "* `scipy.stats.loguniform(a, b)`: when you have almost no idea what the optimal hyperparameter value's scale is. If you set a=0.01 and b=100, then you're just as likely to sample a value between 0.01 and 0.1 as a value between 10 and 100.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg_sAlf9gkUV"
      },
      "source": [
        "Here are plots of the probability mass functions (for discrete variables), and probability density functions (for continuous variables) for `randint()`, `uniform()`, `geom()` and `expon()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "KUQhZxCGgkUV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "\n",
        "xs1 = np.arange(0, 7 + 1)\n",
        "randint_distrib = stats.randint(0, 7 + 1).pmf(xs1)\n",
        "\n",
        "xs2 = np.linspace(0, 7, 500)\n",
        "uniform_distrib = stats.uniform(0, 7).pdf(xs2)\n",
        "\n",
        "xs3 = np.arange(0, 7 + 1)\n",
        "geom_distrib = stats.geom(0.5).pmf(xs3)\n",
        "\n",
        "xs4 = np.linspace(0, 7, 500)\n",
        "expon_distrib = stats.expon(scale=1).pdf(xs4)\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.bar(xs1, randint_distrib, label=\"scipy.randint(0, 7 + 1)\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.legend()\n",
        "plt.axis([-1, 8, 0, 0.2])\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.fill_between(xs2, uniform_distrib, label=\"scipy.uniform(0, 7)\")\n",
        "plt.ylabel(\"PDF\")\n",
        "plt.legend()\n",
        "plt.axis([-1, 8, 0, 0.2])\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.bar(xs3, geom_distrib, label=\"scipy.geom(0.5)\")\n",
        "plt.xlabel(\"Hyperparameter value\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.legend()\n",
        "plt.axis([0, 7, 0, 1])\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.fill_between(xs4, expon_distrib, label=\"scipy.expon(scale=1)\")\n",
        "plt.xlabel(\"Hyperparameter value\")\n",
        "plt.ylabel(\"PDF\")\n",
        "plt.legend()\n",
        "plt.axis([0, 7, 0, 1])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ahtf3ItYgkUV"
      },
      "source": [
        "Here are the PDF for `expon()` and `loguniform()` (left column), as well as the PDF of log(X) (right column). The right column shows the distribution of hyperparameter _scales_. You can see that `expon()` favors hyperparameters with roughly the desired scale, with a longer tail towards the smaller scales. But `loguniform()` does not favor any scale, they are all equally likely:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "rY3Sdq8-gkUV"
      },
      "outputs": [],
      "source": [
        "xs1 = np.linspace(0, 7, 500)\n",
        "expon_distrib = stats.expon(scale=1).pdf(xs1)\n",
        "\n",
        "log_xs2 = np.linspace(-5, 3, 500)\n",
        "log_expon_distrib = np.exp(log_xs2 - np.exp(log_xs2))\n",
        "\n",
        "xs3 = np.linspace(0.001, 1000, 500)\n",
        "loguniform_distrib = stats.loguniform(0.001, 1000).pdf(xs3)\n",
        "\n",
        "log_xs4 = np.linspace(np.log(0.001), np.log(1000), 500)\n",
        "log_loguniform_distrib = stats.uniform(np.log(0.001), np.log(1000)).pdf(log_xs4)\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.fill_between(xs1, expon_distrib, label=\"scipy.expon(scale=1)\")\n",
        "plt.ylabel(\"PDF\")\n",
        "plt.legend()\n",
        "plt.axis([0, 7, 0, 1])\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.fill_between(log_xs2, log_expon_distrib, label=\"log(X) with X ~ expon\")\n",
        "plt.legend()\n",
        "plt.axis([-5, 3, 0, 1])\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.fill_between(xs3, loguniform_distrib, label=\"scipy.loguniform(0.001, 1000)\")\n",
        "plt.xlabel(\"Hyperparameter value\")\n",
        "plt.ylabel(\"PDF\")\n",
        "plt.legend()\n",
        "plt.axis([0.001, 1000, 0, 0.005])\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.fill_between(log_xs4, log_loguniform_distrib, label=\"log(X) with X ~ loguniform\")\n",
        "plt.xlabel(\"Log of hyperparameter value\")\n",
        "plt.legend()\n",
        "plt.axis([-8, 1, 0, 0.2])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wrd6ctYXgkUV"
      },
      "source": [
        "## Analyze the Best Models and Their Errors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_search_cv.best_estimator_"
      ],
      "metadata": {
        "id": "iWQrLCS-vlR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5y8xVelgkUV"
      },
      "outputs": [],
      "source": [
        "feature_importances = (\n",
        "    randomized_search_cv.best_estimator_\n",
        "                        [\"random_forest\"]\n",
        "                        .feature_importances_\n",
        ")\n",
        "feature_importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97y3dZU2gkUV"
      },
      "outputs": [],
      "source": [
        "feature_names = (\n",
        "    randomized_search_cv.best_estimator_\n",
        "                        [\"preprocessing\"]\n",
        "                        .get_feature_names_out()\n",
        ")\n",
        "sorted(zip(feature_importances, feature_names), reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyqDEgWegkUV"
      },
      "source": [
        "## Evaluate Your System on the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLkW-VoHgkUV"
      },
      "outputs": [],
      "source": [
        "test_features_df = test_df.drop(\"median_house_value\", axis=1)\n",
        "test_targets = test_df.loc[:, \"median_house_value\"]\n",
        "\n",
        "test_predictions = (\n",
        "    randomized_search_cv.best_estimator_\n",
        "                        .predict(test_features_df)\n",
        ")\n",
        "\n",
        "metrics.mean_squared_error(\n",
        "    test_targets,\n",
        "    test_predictions,\n",
        "    squared=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B8Na4nlgkUV"
      },
      "source": [
        "We can compute a 95% confidence interval for the test RMSE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4rj3o9NgkUW"
      },
      "outputs": [],
      "source": [
        "confidence = 0.95\n",
        "squared_errors = (test_predictions - test_targets)**2\n",
        "np.sqrt(\n",
        "    stats.t.interval(\n",
        "        confidence,\n",
        "        len(squared_errors) - 1,\n",
        "        loc=squared_errors.mean(),\n",
        "        scale=stats.sem(squared_errors)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEGcDF5jgkUW"
      },
      "source": [
        "We could compute the interval manually like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V40IuZ8JgkUW"
      },
      "outputs": [],
      "source": [
        "m = len(squared_errors)\n",
        "mean = squared_errors.mean()\n",
        "tscore = stats.t.ppf((1 + confidence) / 2, df=m - 1)\n",
        "tmargin = tscore * squared_errors.std(ddof=1) / np.sqrt(m)\n",
        "np.sqrt(mean - tmargin), np.sqrt(mean + tmargin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOI_r8GygkUW"
      },
      "source": [
        "Alternatively, we could use a z-score rather than a t-score. Since the test set is not too small, it won't make a big difference:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86geFnDDgkUW"
      },
      "outputs": [],
      "source": [
        "# extra code â€“ computes a confidence interval again using a z-score\n",
        "zscore = stats.norm.ppf((1 + confidence) / 2)\n",
        "zmargin = zscore * squared_errors.std(ddof=1) / np.sqrt(m)\n",
        "np.sqrt(mean - zmargin), np.sqrt(mean + zmargin)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "nav_menu": {
      "height": "279px",
      "width": "309px"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}